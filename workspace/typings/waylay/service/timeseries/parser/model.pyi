"""
This type stub file was generated by pyright.
"""

import os
import io
import re
import sys
import pandas as pd
from tarfile import TarFile
from typing import Any, Callable, IO, Iterable, Iterator, List, Mapping, Optional, Protocol, Sequence, SupportsInt, Tuple, Union, runtime_checkable
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from dataclasses import dataclass
from zipfile import ZipFile
from waylay.exceptions import RequestError

"""Model objects for the timeseries tool."""
__docformat__ = ...
if sys.version_info > (3, 7):
    Pattern = re.Pattern
else:
    ...
ETL_IMPORT_BUCKET = ...
ETL_IMPORT_UPLOAD_PREFIX = ...
METRIC_PREFIX = ...
METRIC_PREFIX_LENGTH = ...
ETL_IMPORT_COLUMN_NAMES = ...
MeasurementValue = Union[str, int, float, bool, None]
Measurement = Tuple[datetime, MeasurementValue]
MeasurementIterator = Iterator[Measurement]
SeriesProvider = Mapping[Tuple[str, str], Iterable[Measurement]]
SeriesIterator = Iterator[Tuple[str, str, MeasurementIterator]]
CSVReader = Iterator[Sequence[str]]
CSVReaderAndResource = Tuple[CSVReader, Optional[str]]
PathLike = Union[str, os.PathLike]
fromisoformat = ...
MAX_EPOCH_SECONDS = ...
MAX_EPOCH_MILLIS = ...
MAX_EPOCH_MICROS = ...
MAX_EPOCH_NANOS = ...
def parse_timestamp_unix(epoch: Union[str, SupportsInt]) -> pd.Timestamp:
    """Convert a unix epoch to datetime, automatically recognising ranges.

    Assumes that the represented timestamps are before '2262-04-07 16:26:40+0000'
    and after '1970-04-17 17:56:40+0000' (when not using seconds unit).
    (Limitation from 64-bit nanosecond representation used in pandas).
    """
    ...

def parse_timestamp_auto(value: Union[str, SupportsInt]) -> pd.Timestamp:
    """Convert a value to a timestamp, trying epoch or ISO representations."""
    ...

class ParserRequestError(RequestError):
    """Request validation errors in the timeseries etl parser utilities."""
    ...


def try_parse_float(value: str) -> Union[float, str]:
    """Parse a string to a float value or return the orignal value."""
    ...

def parse_float(value: str) -> Optional[float]:
    """Parse a string to a float value or return None."""
    ...

def try_parse_int(value: str) -> Union[int, str]:
    """Parse a string to a int value or return the orignal value."""
    ...

def parse_int(value: str) -> Optional[int]:
    """Parse a string to a int value or return None."""
    ...

def try_parse_bool(value: str) -> Union[str, bool]:
    """Parse a string to a boolean value or return the orignal value."""
    ...

def parse_bool(value: str) -> Optional[bool]:
    """Parse a string to a boolean value or return None."""
    ...

PARSERS_BY_VALUE_TYPE = ...
TIMESTAMP_COLUMN_NAMES = ...
def render_timestamp_zulu(timestamp: datetime) -> str:
    """Render a timestamp into the format used by the ETL service."""
    ...

def parse_timestamp(iso_timestamp: str) -> datetime:
    """Parse a timestamp from the format used by the ETL service."""
    ...

def parse_interval(interval: Optional[Union[str, pd.Timedelta, timedelta]]) -> Optional[timedelta]:
    """Parse a str to a time interval, supports ISO8601 durations."""
    ...

RESOURCE_METADATA_KEY = ...
@dataclass
class Metric:
    """Metadata for a metric (univariate series) within a dataset.

    This holds both specifications inferred from the dataset, as
    given explicitely by the caller.

    Attributes:
        name                The metric name that should be used in waylay
        key                 The key used in the input data set
        value_parser        The (python) parser for this value when reading from csv, e.g. `float`

    Descriptive Attributes:
        value_type          The (javascript) value_type that for this value
        metric_type         The type of metric (`gauge`, `counter`, `rate`, `timestamp` )
        unit                The unit
        description
    """
    name: str
    key: Optional[str] = ...
    value_parser: Optional[Callable[[str], MeasurementValue]] = ...
    description: Optional[str] = ...
    value_type: Optional[str] = ...
    metric_type: Optional[str] = ...
    unit: Optional[str] = ...
    def __post_init__(self): # -> None:
        """Remove legacy prefix from name."""
        ...
    
    @property
    def key_or_name(self): # -> str:
        """Get the data key for this metric, defaulting to the metric name."""
        ...
    
    def get_value_parser(self) -> Callable[[str], MeasurementValue]:
        """Get the parser callback for this metric."""
        ...
    
    def to_dict(self): # -> dict[str, Any]:
        """Convert to a json object representation.

        This format complies with how metric metadata is stored in the Waylay Resource metadata.
        """
        ...
    
    def __repr__(self) -> str:
        """Render as string."""
        ...
    


@dataclass
class Resource:
    """Metadata for a resource (owning entity of series) within a dataset.

    This holds both specifications inferred from the dataset,
    as given explicitely by the caller.

    Attributes:
        id:     The resource id that should be used in waylay
        key:    The key used in the input data set

    Descriptive Attributes:
        name:   The resource name that should be used in waylay
        description: A string description of the resource
        metrics:
            Metadata documentation on the series metrics
            that can be uploaded for this resource.
    """
    id: str
    key: Optional[str] = ...
    description: Optional[str] = ...
    name: Optional[str] = ...
    metrics: Optional[Sequence[Metric]] = ...
    @property
    def key_or_id(self): # -> str:
        """Get the data key for this resource, defaulting to the resource id."""
        ...
    
    def to_dict(self): # -> dict[str, Any]:
        """Convert to a json object representation.

        This format complies with how resource metadata is stored in the Waylay Resource metadata.
        """
        ...
    
    def with_metrics(self, metrics: Sequence[Metric]) -> Resource:
        """Return a copy of this description object with the given metrics instead."""
        ...
    
    def __repr__(self) -> str:
        """Render as string."""
        ...
    


class TimestampFormat(str, Enum):
    """Default timestamp formats for input and output."""
    ISO = ...
    SECONDS = ...
    MILLIS = ...
    MICROS = ...
    NANOS = ...
    UNIX = ...
    AUTO = ...
    description: str
    example: Any
    _spec_matcher: Pattern
    _parse: Tuple[Callable[[Any], datetime]]
    _format: Tuple[Callable[[datetime], Any]]
    _timezone_dependent: bool
    def __new__(cls, value: str, description: str, example: Any, spec_matcher: str, parse_method: Callable[[Any], pd.Timestamp], format_method: Callable[[pd.Timestamp], Any], timezone_dependent: bool = ...): # -> Self:
        """Construct an enum value.

        See https://docs.python.org/3/library/enum.html#when-to-use-new-vs-init.
        """
        ...
    
    @classmethod
    def lookup(cls, spec: Union[str, TimestampFormat]) -> TimestampFormat:
        """Lookup a TimestampFormat from string specification."""
        ...
    
    def parser(self, tz: Any = ...) -> Callable[[Any], pd.Timestamp]:
        """Get a parser that uses a (default) timezone while parsing."""
        ...
    
    def formatter(self, tz: Any = ...) -> Callable[[pd.Timestamp], Any]:
        """Get a formatter that uses a (default) timezone when relevant."""
        ...
    
    def __str__(self) -> str:
        """Get the string representation."""
        ...
    


@dataclass
class SeriesSettings:
    """Settings for the mapping of an input (import) or CSV output (export).

    Attributes:
        metric_column:
            The input attribute containing the metric id.
            This is a column name, or a pandas multiindex level name for the columns.
            If not specified:
            * if a `value_column` is specified, the default "metric" column is uses if present.
            * else, each column name (except the `resource_column` and `timestamp_column` ones),
                is a metric key and provide seperate series.
        metric:
            A default metric name for this import.
        metrics:
            A list of either:
            - metric keys retained from the input
            - `waylay.service.timeseries.parser.model.Metric` entries that describe and map metrics
            If specified, only series for these metrics are processed.
        resource_column:
            The input key containing the resource id.
            This is a column name, or a pandas multiindex level name for the columns.
            If not specified, a fixed `resource` should be specified,
            or the column key "resource" is used if present.
        resource:
            A default resource id to use for this import.
        resources:
            A list of either:
            - resource keys retained from the input
            - `waylay.service.timeseries.parser.model.Resource`
                entries that describe and map resources
            If specified, only series for these resources are processed.
        value_column:
            The column key containing the value. When set, the metric names should be
            provided through `metric` or `metric_column` (default "metric").
        timestamp_column:
            The input key containing the timestamp.
        timestamp_offset:
            A time interval to add to the input timestamp.
        timestamp_first:
            Forces the first timestamp, and increments
            the following timestamps with the same amount.
        timestamp_last:
            Forces the last timestamp, and increments the preceding timestamps with the same amount.
        timestamp_interval:
            Ignores the input timestamps and writes data with fixed timestamp intervals.
            Requires `timestamp_first`.
        timestamp_constructor:
            A callable that creates a `datetime` or `pandas.Timestamp` from the timestamp input.
        timestamp_timezone:
            A timezone indicator that should be used to interpret local time data.
        timestamp_from:
            Filters to have a timestamp equal to or greater than this one.
        timestamp_until:
            Filters to have a timestamp strictly less than this one.
    """
    metrics: Optional[Sequence[Union[str, Metric]]] = ...
    metric_column: Optional[str] = ...
    metric: Optional[str] = ...
    resources: Optional[Sequence[Union[str, Resource]]] = ...
    resource_column: Optional[str] = ...
    resource: Optional[str] = ...
    value_column: Optional[str] = ...
    timestamp_column: Optional[str] = ...
    timestamp_offset: Optional[timedelta] = ...
    timestamp_first: Optional[datetime] = ...
    timestamp_last: Optional[datetime] = ...
    timestamp_interval: Optional[timedelta] = ...
    timestamp_constructor: Optional[Callable[[Any], datetime]] = ...
    timestamp_timezone: Optional[str] = ...
    name: Optional[str] = ...
    timestamp_from: Optional[Any] = ...
    timestamp_until: Optional[Any] = ...
    timestamp_formatter: Optional[Callable[[datetime], Any]] = ...
    timestamp_format: Optional[TimestampFormat] = ...
    write_csv_header: bool = ...
    per_resource: bool = ...
    per_metric: bool = ...
    skip_empty_values = ...
    def __post_init__(self): # -> None:
        """Parse string input args to objects."""
        ...
    
    def iter_metrics(self) -> Iterator[Metric]:
        """Iterate the metric specifications if available."""
        ...
    
    def iter_resources(self) -> Iterator[Resource]:
        """Iterate the resource specifications if available."""
        ...
    
    def metric_by_key(self, key: Optional[str]) -> Optional[str]:
        """Lookup the actual metric name for the given column key."""
        ...
    
    def key_by_metric(self, name: str) -> Optional[str]:
        """Lookup the column key that is used to represent the a given metric name.

        The empty key resolves to the default metric.
        """
        ...
    
    def resource_by_key(self, key: Optional[str]) -> Optional[str]:
        """Lookup the actual resource id for the given resource key.

        The empty key resolves to the default resource.
        """
        ...
    
    def key_by_resource(self, resource_id: str) -> Optional[str]:
        """Lookup the column key that is used to represent the a given resource id."""
        ...
    
    def has_timestamp(self) -> bool:
        """Check wether the dataset should deliver timestamps."""
        ...
    
    def metric_for(self, metric_name: str) -> Metric:
        """Create a metadata object for the given metric names.

        Uses the `metrics` registered on this object as a data description catalog.
        """
        ...
    
    def resource_for(self, resource_id: str, metric_names: Optional[Sequence[str]] = ...) -> Resource:
        """Create a metadata object for the given resource id and metric names.

        Uses the `resources` and `metrics` registered on this object as a data
        description catalog to enhance the _resource_ and _metric_
        references found in a concrete series.
        """
        ...
    
    def get_timestamp_formatter(self) -> Callable[[datetime], Any]:
        """Get the formatter for timestamps in csv exports."""
        ...
    
    def get_timestamp_parser(self, example: Any = ...) -> Callable[[Any], datetime]:
        """Get the parser for timestamps in csv imports."""
        ...
    
    def parse_timestamp(self, value: Any) -> Optional[datetime]:
        """Parse a timestamp, fall back to ISO."""
        ...
    
    def get_timestamp_from(self) -> Optional[datetime]:
        """Get the from timestamp, if any."""
        ...
    
    def get_timestamp_until(self) -> Optional[datetime]:
        """Get the until timestamp, if any."""
        ...
    


@dataclass
class ETLFile:
    """Defines a local ETL export/import file and workspace.

    Attributes:
        directory:
            The (local) directory used to store the ETL file and associated temporary files.
        prefix:
            The prefix used to create the ETL file. If not specified
            is defaulted to `import-{current timestamp}`.
    """
    directory: Optional[PathLike] = ...
    prefix: Optional[str] = ...
    def __post_init__(self): # -> None:
        """Compute default prefix if not given as constructor parameter."""
        ...
    
    @property
    def name(self) -> str:
        """Get the name of the ETL file."""
        ...
    
    @property
    def path(self) -> Path:
        """Get the full path of the ETL file."""
        ...
    


SeriesInput = Union[ETLFile, pd.DataFrame, str, os.PathLike, io.TextIOBase, Iterable[str], Iterable[Sequence[str]],]
@dataclass
class WaylayETLSeriesImport:
    """A (reference to) a local file in the waylay ETL timeseries format and associated metadata."""
    series_input: Sequence[SeriesInput] = ...
    import_file: ETLFile
    settings: SeriesSettings
    storage_bucket: str = ...
    @property
    def storage_object_name(self): # -> str:
        """Get default upload storage location."""
        ...
    
    @property
    def name(self): # -> str | None:
        """Get the name that identifies the import."""
        ...
    


@runtime_checkable
class CSVWriteable(Protocol):
    """Aything that can receive string writes."""
    def write(self, _: str) -> Any:
        """Write a string."""
        ...
    


CSVOutput = Union[str, os.PathLike, IO, CSVWriteable, ZipFile, TarFile]
class ArchiveType(str, Enum):
    """Typed enumeration of supported archive import and export types."""
    description: str
    supports_multiple_files: bool
    expected_suffixes: List[str]
    excluded_suffixes: List[str]
    is_dir_type: bool
    def __new__(cls, value: str, description: str, supports_multiple_files: bool, expected_suffixes: Optional[List[str]] = ..., excluded_suffixes: Optional[List[str]] = ..., is_dir_type: bool = ...): # -> Self:
        """Construct an enum value.

        See https://docs.python.org/3/library/enum.html#when-to-use-new-vs-init.
        """
        ...
    
    TEXT = ...
    DIR = ...
    DIR_GZ = ...
    ZIP = ...
    GZ = ...
    TAR = ...
    TAR_GZ = ...
    def __str__(self) -> str:
        """Get the string representation."""
        ...
    
    @classmethod
    def lookup(cls, value: Optional[str]) -> Optional[ArchiveType]:
        """Lookup an enum object from a str value."""
        ...
    
    @classmethod
    def supported_for(cls, path: Path, multiple_files: bool) -> List[ArchiveType]:
        """Return a list of supported archive types, given a path and multiple_files flag."""
        ...
    
    @classmethod
    def for_import(cls, path: Path) -> Optional[ArchiveType]:
        """Return the archive type for import, as inferred from an existing file name."""
        ...
    



"""
This type stub file was generated by pyright.
"""

import pandas as pd
from typing import Any, Dict, Iterator, List, Optional, Union
from enum import Enum
from dataclasses import dataclass
from contextlib import contextmanager
from waylay.exceptions import WaylayError
from waylay.service import WaylayResource
from waylay.service.storage import StorageService
from waylay.service.etl import ETLService
from waylay.service.resources import ResourcesService
from waylay.service.data import DataService
from waylay.service.queries import QueriesService
from waylay.service._base import WaylayServiceContext
from .parser.model import CSVOutput, CSVReader, PathLike, Resource, SeriesInput, SeriesSettings, WaylayETLSeriesImport

"""ETL import tooling."""
__docformat__ = ...
LOG = ...
ETL_IMPORT_TIMESERIES_FILE_SUFFIX = ...
ETL_IMPORT_RESULT_FILE_SUFFIX = ...
ETL_IMPORT_SUFFIXES = ...
class ETLImportError(WaylayError):
    """Error raised when the ETL tool is not able to fullfill the requested operation."""
    ...


class ResourceUpdateLevel(str, Enum):
    """The possible detail levels at which Waylay Resources can be updated during an ETL import job."""
    NONE = ...
    ID = ...
    ALL = ...
    def __str__(self) -> str:
        """Get the string representation."""
        ...
    


class ETLImportStatus(str, Enum):
    """The possible states of an ETL import job.

    These correspond to the subfolders of the 'etl-import' bucket (except for 'not_found').
    """
    UPLOAD = ...
    BUSY = ...
    FAILED = ...
    IGNORED = ...
    DONE = ...
    NOT_FOUND = ...
    def __str__(self) -> str:
        """Get the string representation."""
        ...
    


ETL_IMPORT_STATUS_MESSAGE = ...
ETL_IMPORT_UPLOAD_PROCESS_STATUSES = ...
ETL_IMPORT_ALLOW_CLEANUP_STATUSES = ...
@dataclass
class ETLImportJob:
    """Response object for the status of an etl upload.

    Reports the status of an ETL import job as executed by the ETL Server and recorded in
    the 'etl-import' storage bucket.

    Attributes:
        name: The (base) name of the ETL file as a storage object in the 'etl-import' bucket.
        message: A human readable status message.
        status: The import job status.
        storage: A link to the storage location.
        etl_import:
            The response object of the ETL Server for this job,
            as stored on the 'etl-import' bucket.
        last_etl_import:
            The response object of the last job handled by the ETL Server.
            Only included when inspecting the status of a specific upload ('check_import').
    """
    name: str
    message: str
    status: ETLImportStatus
    storage_name: Optional[str] = ...
    storage_get_url: Optional[str] = ...
    etl_import: Optional[Dict] = ...
    last_etl_import: Optional[Dict] = ...
    @property
    def storage(self) -> str:
        """Get a html link to the import file as stored on Waylay Storage."""
        ...
    
    @property
    def storage_folder(self) -> Optional[str]:
        """Get the storage folder in which the import file and its status report resides."""
        ...
    
    def to_dict(self) -> Dict[str, Any]:
        """Return a dict representation."""
        ...
    
    def to_dataframe(self) -> pd.DataFrame:
        """Return a dataframe representation."""
        ...
    
    def to_html(self) -> str:
        """Return an HTML string representation."""
        ...
    


class TimeSeriesETLTool(WaylayResource):
    """Client tool to prepare and upload or download timeseries data.

    Attributes:
        storage_service:
            Storage service client used by this tool.
        etl_service:
            ETL service client used by this tool.
        temp_dir:
            Default temporary directory used for processes initiated by this tool.
    """
    actions: Dict[str, Any] = ...
    storage_service: StorageService
    etl_service: ETLService
    resources_service: ResourcesService
    query_service: QueriesService
    data_service: DataService
    temp_dir: Optional[PathLike] = ...
    def set_context(self, service_context: WaylayServiceContext): # -> None:
        """Configure this tool with a service context."""
        ...
    
    def prepare_import(self, *series: SeriesInput, name: Optional[str] = ..., temp_dir: Optional[PathLike] = ..., settings: Optional[SeriesSettings] = ..., progress: bool = ..., **settings_args: Any) -> WaylayETLSeriesImport:
        """Convert an input data set to a locally stored timeseries file.

This created file can be ingested by the waylay system as timeseries data.

Arguments:
    series: A supported CSV or pandas Dataframe input source.
    name:
        A name for the upload job, will be used in naming the ETL file.
        (default: 'import-{timestamp}')
    temp_dir:
        The local storage location to use in preparing the ETL file.
        (default: a system generated temp file with prefix 'etl-import')
    settings:
        A full specification object for the data conversion. Alternatively,
        attributes of this `SeriesSettings` object can be specified as keyword
        argument.
    progress:
        Write a progress bar for the conversion to standard output.
    **settings_args:
        Any attribute of a `SeriesSettings` object. See `settings` above.
        """
        ...
    
    def initiate_import(self, etl_import: WaylayETLSeriesImport, resource_update_level: ResourceUpdateLevel = ..., progress: bool = ...) -> WaylayETLSeriesImport:
        """Upload a prepared timeseries file to the etl-import ingestion bucket.

Arguments:
    etl_import:
        A reference object to the input source and converted etl file, as
        produced by `prepare_import`.
        """
        ...
    
    def list_import(self, name_filter: Optional[str] = ..., status_filter: Optional[List[ETLImportStatus]] = ...) -> List[ETLImportJob]:
        """List all imports in all states on the `etl-import` bucket.

This queries both the content of the `etl-import` bucket,
and the current or last job held by the ETL Service.

Arguments:
    name_filter:
        A query filter on the name of the etl import files to consider.
    status_filter:
        A filter on the status of the import jobs, a list of strings
        as enumerated in `ETLImportStatus`

Returns:
    A list of 'ETLImportJob' objects that represent the processing status
    of an ETL import job.
        """
        ...
    
    def check_import(self, etl_import: Union[str, ETLImportJob, WaylayETLSeriesImport]) -> ETLImportJob:
        """Validate the status of an import process started by this tool.

Arguments:
    etl_import:
        Either a `WaylayETLSeriesImport`, representing a prepared import task,
        as produced by `initiate_import`,
        or an `ETLImportJob`, representing the status of that task,
        as returned by `list_import`, `check_import`
        or a the name of an import job.
Returns:
    An object representing the current status of the ETL import job.
        """
        ...
    
    def cleanup_import(self, etl_import: Union[str, WaylayETLSeriesImport, ETLImportJob], force: bool = ...) -> ETLImportJob:
        """Clean up the server storage for an import task.

Arguments:
    etl_import:
        Either a `WaylayETLSeriesImport`, representing a prepared import task,
        as produced by `initiate_import`,
        or an `ETLImportJob`, representing the status of that task,
        as returned by `list_import`, `check_import`.
    force:
        If true, delete storage even if the import job is reported
        to be running or not existing.

Returns:
    An object representing the current status of the ETL import job.

        """
        ...
    
    @contextmanager
    def read_import_as_csv(self, etl_import: WaylayETLSeriesImport) -> Iterator[CSVReader]:
        """Read an etl import file as a csv stream.

This returns a context manager that provides an iterator
of csv rows (`Iterator[Sequence[str]]`):

    with etl_tool.read_import_as_csv(etl_import) as csv_data:
        for csv_line in csv_data:
            print("|".join(csv_line))

Arguments:
    etl_import:
        The object representing the converted ETL import file,
        as produced by `prepare_import`.

Returns:
    A context manager providing an iterator of string records.

        """
        ...
    
    def read_import_as_dataframe(self, etl_import: WaylayETLSeriesImport) -> pd.DataFrame:
        """Read an etl import file as pandas dataframe.

Arguments:
    etl_import:
        The object representing the converted ETL import file,
        as produced by `prepare_import`.

Returns:
    A pandas Dataframe containing the import data.
    Each series is a seperate column. Column headers
    contain a `resource` and `metric` reference.
    When the input specification of the `etl_import` contains
    a `metrics` object with a `value_type` or `value_parser` attribute,
    the corresponding csv series is converted to that data type.
        """
        ...
    
    def list_import_resources(self, etl_import: WaylayETLSeriesImport) -> List[Resource]:
        """List resource and metric metadata contained in an ETL import file.

Arguments:
    etl_import:
        The object representing the converted ETL import file,
        as produced by `prepare_import`.

Returns:
    A list of `Resource` metadata objects describing the
    content of the import file.
        """
        ...
    
    def update_resources(self, etl_import: WaylayETLSeriesImport, resource_update_level: ResourceUpdateLevel = ...) -> List[Resource]:
        """Create or update the Waylay Resources for the timeseries in this dataset.

Arguments:
    etl_import:
        The object representing the converted ETL import file,
        as produced by `prepare_import`.

Returns:
    A list of `Resource` metadata objects describing the
    content of the import file, and for which metadata has been updated
    to the waylay system
        """
        ...
    
    def update_query(self, etl_import: WaylayETLSeriesImport, name: Optional[str] = ..., **query_params: Any) -> Any:
        """Create or update a waylay query containing all the series defined in this import.

The name of the import will be used as query name.
Arguments:
    etl_import:
        The object representing the converted ETL import file,
        as produced by `prepare_import`.
    name:
        The name of the query. Defaults to the prefix name of
        the etl_import argument (`etl_import.import_file.prefix`).
    query_params:
        Any additional query params (like `from`, `util`, `freq`, `aggregation`, ...)
        to be used in the query

Returns:
    The result of a `queries.query.replace()` SDK call that
    updated or created the query with the name of the import.
        """
        ...
    
    def export_series_as_csv(self, output: CSVOutput, archive_type: Optional[str] = ..., progress: bool = ..., settings: Optional[SeriesSettings] = ..., timestamp_column: Optional[str] = ..., **settings_args: Any): # -> None:
        """Export a number of series from the times series database.

    Arguments:
        output:
            The object to which the csv lines will be written. Can be a file path, stream, etc.
        archive_type:
            Optional archive type.
        progress:
            Optional boolean to write a progress bar for the export.
        settings:
            Optional series settings.
        timestamp_column:
            Optional name for timestamp column. Defaults to 'timestamp'. Set to None if not wanted.
        """
        ...
    


